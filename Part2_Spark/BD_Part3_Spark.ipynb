{"cells":[{"cell_type":"markdown","metadata":{"id":"7p3NGLZUqp3V"},"source":["Install and Setup Spark"]},{"cell_type":"code","execution_count":122,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25595,"status":"ok","timestamp":1716991325301,"user":{"displayName":"Yosef Gerstein","userId":"10395506133134584091"},"user_tz":-180},"id":"VQ67FxxHpC1F","outputId":"231019f2-39e0-4167-88f4-6971b7a04ec4"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[33m\r0% [Working]\u001b[0m\r            \rHit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n","\u001b[33m\r0% [Connecting to security.ubuntu.com (185.125.190.36)] [Connected to cloud.r-project.org (108.157.1\u001b[0m\r                                                                                                    \rGet:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n","\u001b[33m\r0% [2 InRelease 12.7 kB/128 kB 10%] [Waiting for headers] [Waiting for headers] [Connecting to ppa.l\u001b[0m\r                                                                                                    \rHit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n","\u001b[33m\r0% [2 InRelease 15.6 kB/128 kB 12%] [Waiting for headers] [Waiting for headers] [Connecting to ppa.l\u001b[0m\r                                                                                                    \rHit:4 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n","\u001b[33m\r0% [2 InRelease 15.6 kB/128 kB 12%] [Waiting for headers] [Connecting to ppa.launchpadcontent.net (1\u001b[0m\u001b[33m\r                                                                                                    \r0% [Waiting for headers] [Connecting to ppa.launchpadcontent.net (185.125.190.80)]\u001b[0m\r                                                                                  \rGet:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n","Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n","Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,125 kB]\n","Hit:8 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n","Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n","Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n","Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n","Fetched 2,382 kB in 2s (1,249 kB/s)\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","47 packages can be upgraded. Run 'apt list --upgradable' to see them.\n"]}],"source":["# 1) First: install Java, Spark and and run a local Spark session by just running this on Google Colab:\n","!apt update\n","!apt-get install openjdk-8-jdk-headless -qq > /dev/null   # !apt-get --> install java\n","#!wget -q https://dlcdn.apache.org/spark/spark-3.3.4/spark-3.3.4-bin-hadoop3.tgz\n","!wget -q https://dlcdn.apache.org/spark/spark-3.5.1/spark-3.5.1-bin-hadoop3.tgz\n","!tar xf spark-3.5.1-bin-hadoop3.tgz  # !tar --> like unzip\n","!pip install -q findspark  # !pip  --> instal a package, we cant import a library without installing it first, most libraries that we used were already installed\n","\n","# 2) Set the locations where Spark and Java are installed to let know Colab where to find it.\n","import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.1-bin-hadoop3\"\n","\n","\n","# 3) Third: import spark libraries and use them\n","import findspark\n","findspark.init(\"spark-3.5.1-bin-hadoop3\")\n","from pyspark.sql import SparkSession\n","spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n","from pyspark.sql import Row\n","from pyspark.sql import functions"]},{"cell_type":"code","execution_count":123,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1716991325301,"user":{"displayName":"Yosef Gerstein","userId":"10395506133134584091"},"user_tz":-180},"id":"8ZhU7pKGpb58"},"outputs":[],"source":["spark = SparkSession.builder.appName(\"Basic\").getOrCreate()"]},{"cell_type":"markdown","metadata":{"id":"VFPBRR4CqxJ6"},"source":["Mount Google Drive"]},{"cell_type":"code","execution_count":124,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3680,"status":"ok","timestamp":1716991328975,"user":{"displayName":"Yosef Gerstein","userId":"10395506133134584091"},"user_tz":-180},"id":"F7Hz9uwQpcCO","outputId":"2a381629-cf35-4d95-c0aa-b40913a999b1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"DzhK5ghJqzvo"},"source":["Import churn_and_rating file"]},{"cell_type":"code","execution_count":125,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1716991328975,"user":{"displayName":"Yosef Gerstein","userId":"10395506133134584091"},"user_tz":-180},"id":"d-V9x8G7pcEy","outputId":"6083ba59-0589-4f5f-db8c-bafe1b74ed73"},"outputs":[{"name":"stdout","output_type":"stream","text":["'/content/drive/MyDrive/Spark/Part C - Spark Project/churn_location_and_rating.csv'\n"]}],"source":["path = \"/content/drive/MyDrive/Spark/Part C - Spark Project/churn_location_and_rating.csv\"\n","!ls \"/content/drive/MyDrive/Spark/Part C - Spark Project/churn_location_and_rating.csv\""]},{"cell_type":"markdown","metadata":{"id":"dP4cpscXqO6Q"},"source":["Import Necessary Libraries"]},{"cell_type":"code","execution_count":126,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13794,"status":"ok","timestamp":1716991342764,"user":{"displayName":"Yosef Gerstein","userId":"10395506133134584091"},"user_tz":-180},"id":"WUOXVapidzit","outputId":"82985c7f-327a-4dd0-9f83-ce08e1cf7fda"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: pycountry in /usr/local/lib/python3.10/dist-packages (23.12.11)\n"]}],"source":["!pip install pycountry"]},{"cell_type":"code","execution_count":127,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1716991342764,"user":{"displayName":"Yosef Gerstein","userId":"10395506133134584091"},"user_tz":-180},"id":"ywdY9JSnpcHK"},"outputs":[],"source":["from pyspark.sql.types import (StructField, IntegerType,StringType, StructType)\n","from pyspark.sql.functions import when\n","from pyspark.sql.functions import countDistinct, avg\n","from pyspark.sql.functions import format_number\n","from pyspark.sql.functions import col, when, split, trim ,regexp_replace\n","import pycountry\n","import re\n","from pyspark.sql.functions import udf"]},{"cell_type":"markdown","metadata":{"id":"7BxcDyuXytxa"},"source":["Creating the Data Source"]},{"cell_type":"code","execution_count":128,"metadata":{"executionInfo":{"elapsed":598,"status":"ok","timestamp":1716991343357,"user":{"displayName":"Yosef Gerstein","userId":"10395506133134584091"},"user_tz":-180},"id":"XNLafPVdpcJw"},"outputs":[],"source":["df = spark.read.csv(\"/content/drive/MyDrive/Spark/Part C - Spark Project/churn_location_and_rating.csv\", header=True, inferSchema=True)"]},{"cell_type":"code","execution_count":129,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":385,"status":"ok","timestamp":1716991343740,"user":{"displayName":"Yosef Gerstein","userId":"10395506133134584091"},"user_tz":-180},"id":"Md-4uaqopcMU","outputId":"05d612ef-e85e-45d6-e047-6a719a2b45fa"},"outputs":[{"name":"stdout","output_type":"stream","text":["+--------------------------+\n","|customerID;Location;Rating|\n","+--------------------------+\n","|      \"id7044;nyc; new ...|\n","|      \"id7045;stockton;...|\n","|      \"id7046;moscow; y...|\n","|      \"id7047;porto; v....|\n","|      \"id7048;farnborou...|\n","|      \"id7049;santa mon...|\n","|      \"id7050;washingto...|\n","|      \"id7051;timmins; ...|\n","|      \"id7052;germantow...|\n","|      \"id7053;albacete;...|\n","|      \"id7054;melbourne...|\n","|      \"id7055;fort brag...|\n","|      \"id7056;barcelona...|\n","|      \"id7057;mediapoli...|\n","|      \"id7058;calgary; ...|\n","|      \"id7059;albuquerq...|\n","|      \"id7060;chesapeak...|\n","|      \"id7061;rio de ja...|\n","|      \"id7062;weston; ;...|\n","|      \"id7063;langhorne...|\n","+--------------------------+\n","only showing top 20 rows\n","\n"]}],"source":["df.show()"]},{"cell_type":"code","execution_count":130,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1716991343741,"user":{"displayName":"Yosef Gerstein","userId":"10395506133134584091"},"user_tz":-180},"id":"5JKrp8alzR0j","outputId":"b263bd7f-8b21-4c68-9074-d64c6a3a32aa"},"outputs":[{"data":{"text/plain":["['customerID;Location;Rating']"]},"execution_count":130,"metadata":{},"output_type":"execute_result"}],"source":["df.columns #one big column that needs to be split"]},{"cell_type":"markdown","metadata":{"id":"e-R3Nt-WbsMb"},"source":["Cleaning and preping the data. Becareful of the n/a and blanks not reading as nulls"]},{"cell_type":"code","execution_count":131,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4918,"status":"ok","timestamp":1716991348655,"user":{"displayName":"Yosef Gerstein","userId":"10395506133134584091"},"user_tz":-180},"id":"WPZzLFHwzR5z","outputId":"b4463226-ae8e-4b35-c131-caf1e1b7ac21"},"outputs":[{"name":"stdout","output_type":"stream","text":["+----------+--------------+--------------+------+--------------+\n","|CustomerId|          City|         State|Rating|       Country|\n","+----------+--------------+--------------+------+--------------+\n","|    id7254|        lleida|        lleida|   1.0|         spain|\n","|    id7317|       bologna|emilia romagna|   5.0|         italy|\n","|    id7435|     barcelona|     catalunya|   6.0|         spain|\n","|    id7504|     singapore|       Unknown|   5.0|     singapore|\n","|    id7875|        mobile|       alabama|   8.0|united kingdom|\n","|    id7879|virginia beach|      virginia|   9.0|           usa|\n","|    id8184|      santiago|       Unknown|   3.0|         chile|\n","|    id8475|       roxbury| massachusetts|   2.0|           usa|\n","|    id8530|    saint paul|     minnesota|   5.0|           usa|\n","|    id8605|          reno|        nevada|   5.0|           usa|\n","|    id8649|   san antonio|         texas|   5.0|           usa|\n","|    id9055|          bray|       wicklow|   4.0|       Unknown|\n","|    id9395|       Unknown|       Unknown|   4.0|       germany|\n","|    id9539|         braga|         minho|   2.0|      portugal|\n","|    id9567|          lodz|          lodz|   5.0|        poland|\n","|    id9716|      lawrence|        kansas|   7.0|           usa|\n","|    id9724|  christchurch|    canterbury|   5.0|   new zealand|\n","|    id9821| granite falls|north carolina|   6.0|           usa|\n","|    id9949|         paris| ile de france|   8.0|        france|\n","|   id10074|       chester|       vermont|   9.0|           usa|\n","+----------+--------------+--------------+------+--------------+\n","only showing top 20 rows\n","\n"]}],"source":["# Rename the single column to a temporary name\n","df = df.toDF(\"combined\")\n","\n","# Clean the combined column to remove any extraneous double quotes\n","df = df.withColumn(\"combined\", regexp_replace(col(\"combined\"), '\"', ''))\n","\n","# Split the single column into CustomerId, City, State, Rating, and Country\n","split_cols = split(df[\"combined\"], ';')\n","df = df.withColumn(\"CustomerId\", trim(split_cols.getItem(0))) \\\n","       .withColumn(\"City\", trim(split_cols.getItem(1))) \\\n","       .withColumn(\"State\", trim(split_cols.getItem(2))) \\\n","       .withColumn(\"Rating\", trim(split_cols.getItem(3))) \\\n","       .withColumn(\"Country\", trim(split_cols.getItem(4))) \\\n","       .drop(\"combined\")\n","\n","# Handle null values and clean incorrect characters\n","df = df.withColumn(\"City\", when((col(\"City\").isNull()) | (col(\"City\") == \"\") | (col(\"City\") == \"n/a\") | (col(\"City\").rlike(r'[^a-zA-Z\\s]')), \"Unknown\").otherwise(col(\"City\")))\n","df = df.withColumn(\"State\", when((col(\"State\").isNull()) | (col(\"State\") == \"\") | (col(\"State\") == \"n/a\") | (col(\"State\").rlike(r'[^a-zA-Z\\s]')), \"Unknown\").otherwise(col(\"State\")))\n","df = df.withColumn(\"Country\", when((col(\"Country\").isNull()) | (col(\"Country\") == \"\") | (col(\"Country\") == \"n/a\") | (col(\"Country\").rlike(r'[^a-zA-Z\\s]')), \"Unknown\").otherwise(col(\"Country\")))\n","df = df.withColumn(\"Rating\", when((col(\"Rating\").isNull()) | (col(\"Rating\") == \"\") | (col(\"Rating\") == \"n/a\"), -1).otherwise(col(\"Rating\")))\n","\n","#two rows with these non 1 to 10 values. Additionally these rows have no additional value (unknowns or random string of letters). Will delete\n","df = df.filter(~col(\"Rating\").isin([\"&#25289\", \"&#24029\"]))\n","\n","# Handle duplicate rows\n","df = df.dropDuplicates()\n","\n","# Show the resulting DataFrame\n","df.show()"]},{"cell_type":"markdown","metadata":{"id":"YwFc-nzxgxz8"},"source":["Clean and Validate Country column"]},{"cell_type":"code","execution_count":132,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3857,"status":"ok","timestamp":1716991352509,"user":{"displayName":"Yosef Gerstein","userId":"10395506133134584091"},"user_tz":-180},"id":"B1HjyiUqzR76","outputId":"192482fe-1ee9-4fc6-e206-dbffe635129b"},"outputs":[{"name":"stdout","output_type":"stream","text":["+----------+--------------+--------------+------+--------------+\n","|CustomerId|          City|         State|Rating|       Country|\n","+----------+--------------+--------------+------+--------------+\n","|    id7254|        lleida|        lleida|   1.0|         Spain|\n","|    id7317|       bologna|emilia romagna|   5.0|         Italy|\n","|    id7435|     barcelona|     catalunya|   6.0|         Spain|\n","|    id7504|     singapore|       Unknown|   5.0|     Singapore|\n","|    id7875|        mobile|       alabama|   8.0|United Kingdom|\n","|    id7879|virginia beach|      virginia|   9.0| United States|\n","|    id8184|      santiago|       Unknown|   3.0|         Chile|\n","|    id8475|       roxbury| massachusetts|   2.0| United States|\n","|    id8530|    saint paul|     minnesota|   5.0| United States|\n","|    id8605|          reno|        nevada|   5.0| United States|\n","|    id8649|   san antonio|         texas|   5.0| United States|\n","|    id9055|          bray|       wicklow|   4.0|       Unknown|\n","|    id9395|       Unknown|       Unknown|   4.0|       Germany|\n","|    id9539|         braga|         minho|   2.0|      Portugal|\n","|    id9567|          lodz|          lodz|   5.0|        Poland|\n","|    id9716|      lawrence|        kansas|   7.0| United States|\n","|    id9724|  christchurch|    canterbury|   5.0|   New Zealand|\n","|    id9821| granite falls|north carolina|   6.0| United States|\n","|    id9949|         paris| ile de france|   8.0|        France|\n","|   id10074|       chester|       vermont|   9.0| United States|\n","+----------+--------------+--------------+------+--------------+\n","only showing top 20 rows\n","\n"]}],"source":["def getcountry(country):\n","    if not country:\n","        return \"Unknown\"\n","\n","    # Remove incorrect characters and clean the country name\n","    country = re.sub(r'[^a-zA-Z\\s]', '', country).strip().lower()\n","\n","    # Try to match the country name with pycountry's list of countries\n","    for country_info in pycountry.countries:\n","        if country in [country_info.name.lower(), country_info.alpha_2.lower(), country_info.alpha_3.lower()]:\n","            return country_info.name\n","\n","    # If no match is found, return the cleaned country name or \"Unknown\"\n","    return \"Unknown\"\n","\n","# Register the UDF\n","getcountry_udf = udf(getcountry, StringType())\n","\n","# Apply the UDF to the \"Country\" column\n","df = df.withColumn(\"Country\", getcountry_udf(col(\"Country\")))\n","\n","# Clean the 'City' and 'State' columns without validation\n","df = df.withColumn(\"City\", trim(col(\"City\"))) \\\n","       .withColumn(\"State\", trim(col(\"State\")))\n","\n","# Show the resulting DataFrame\n","df.show()"]},{"cell_type":"markdown","metadata":{"id":"CTYmY9bvjD2X"},"source":["Download the cleaned CSV"]},{"cell_type":"code","execution_count":133,"metadata":{"executionInfo":{"elapsed":20669,"status":"ok","timestamp":1716991373177,"user":{"displayName":"Yosef Gerstein","userId":"10395506133134584091"},"user_tz":-180},"id":"CLUtJkNxlJ0c"},"outputs":[],"source":["df.coalesce(1).write.csv(\"/content/drive/MyDrive/Spark/Part C - Spark Project/clean_churn_location_rating.csv\", header=True)"]},{"cell_type":"markdown","metadata":{},"source":["Convert to Pandas dataframe for one clean CSV"]},{"cell_type":"code","execution_count":134,"metadata":{"executionInfo":{"elapsed":2086,"status":"ok","timestamp":1716991375256,"user":{"displayName":"Yosef Gerstein","userId":"10395506133134584091"},"user_tz":-180},"id":"yiffTDC6mlNR"},"outputs":[],"source":["import pandas as pd\n","\n","# Read the part files back into a DataFrame\n","df = spark.read.csv(\"/content/drive/MyDrive/Spark/Part C - Spark Project/clean_churn_location_rating.csv\", header=True, inferSchema=True)\n","\n","# Convert the Spark DataFrame to a Pandas DataFrame\n","pandas_df = df.toPandas()\n","\n","# Save the Pandas DataFrame as a single CSV file\n","pandas_df.to_csv(\"/content/drive/MyDrive/Spark/Part C - Spark Project/clean_churn_location_rating_single.csv\", index=False)"]},{"cell_type":"markdown","metadata":{"id":"-G-Sjqf9jG-_"},"source":["Stop Spark"]},{"cell_type":"code","execution_count":135,"metadata":{"executionInfo":{"elapsed":725,"status":"ok","timestamp":1716991375978,"user":{"displayName":"Yosef Gerstein","userId":"10395506133134584091"},"user_tz":-180},"id":"lWG3TkfupcUX"},"outputs":[],"source":["spark.stop()"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPtkZolptXihAoXRPHHfnyq","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
